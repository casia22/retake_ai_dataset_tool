{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46561b08-ebbb-44c0-b6b4-a80373e96b38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import psutil\n",
    "import cv2\n",
    "from concurrent.futures import ProcessPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63396fa9-83b0-47b4-870d-17ba795478ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c18f7621-da64-40c6-850a-05b30ee93904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images(img_paths, img_shape):\n",
    "    img_array = np.zeros((len(img_paths),img_shape[0],img_shape[1],img_shape[2]), dtype=np.uint8)\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f'None image at: {img_path} \\n')\n",
    "            img = np.zeros(img_shape, dtype=np.uint8)\n",
    "        img_array[i, :, :, :] = img_preprocess(img)\n",
    "    return img_array\n",
    "\n",
    "def parallel_load_images(img_paths, img_shape, num_workers=20):\n",
    "    img_chunks = np.array_split(img_paths, num_workers)\n",
    "    results = None\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(load_images, chunk, img_shape) for chunk in img_chunks]\n",
    "        results = [f.result() for f in futures]\n",
    "    return np.concatenate(results, axis=0)\n",
    "\n",
    "def get_label_img_array(path, img_shape, base_path):\n",
    "    with open(path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # skip the csv header\n",
    "        next(reader)\n",
    "        img_paths = [row[-1] for row in reader]\n",
    "        img_paths = [base_path + path for path in img_paths]\n",
    "        \n",
    "        # fill the img_array and label_array\n",
    "    img_array = parallel_load_images(img_paths, img_shape)\n",
    "          \n",
    "    with open(path, 'r') as f:                   \n",
    "        reader = csv.reader(f)    \n",
    "        # skip the csv header    \n",
    "        next(reader)            \n",
    "        # get label array   \n",
    "        label_array = np.array([row[:-1] for row in reader], dtype=np.float32)\n",
    "    # print current ram usage\n",
    "    #print('ram usage: ', psutil.virtual_memory().percent)\n",
    "    # estimate the ram usage of the img_array and label_array\n",
    "    img_array_size = img_array.nbytes / 1024 / 1024\n",
    "    label_array_size = label_array.nbytes / 1024 / 1024\n",
    "    print(f'img_array_size = {img_array_size:.2f} MB')\n",
    "    #print(f'label_array_size = {label_array_size:.2f} MB')\n",
    "    return img_array, label_array\n",
    "\n",
    "def img_preprocess(img):\n",
    "    # resize to 1080p\n",
    "    img = cv2.resize(img, (1920,1080))\n",
    "    # center crop\n",
    "    height, width, _ = img.shape\n",
    "    crop_size = (500, 800)         \n",
    "    center_x = width // 2\n",
    "    center_y = height // 2\n",
    "    crop_x = center_x - crop_size[1] // 2\n",
    "    crop_y = center_y - crop_size[0] // 2\n",
    "    crop_x2 = crop_x + crop_size[1]\n",
    "    crop_y2 = crop_y + crop_size[0]\n",
    "    img = img[crop_y:crop_y2,crop_x:crop_x2,:]\n",
    "    img = cv2.resize(img,(200,125))\n",
    "    # resize for performance\n",
    "    assert img.shape == img_shape#(125, 200, 3)\n",
    "    return img\n",
    "\n",
    "# define a function to add a trajectory to the h5 file\n",
    "def put_trajectory_to_h5(h5_file, img_array, label_array):\n",
    "    pre_round =h5_file[\"data\"].shape[0]\n",
    "    print(f\"-------------------------添加第{pre_round+1}回合-{img_array.shape[0]}帧---------------------------\")\n",
    "    # if len < 20 then refuse to add\n",
    "    if img_array.shape[0] < 20:\n",
    "        print('回合长度 < 20, 不添加')\n",
    "        return\n",
    "    if np.sum(label_array[:,2:]) < 20:\n",
    "        print('回合行为异常，不添加')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # truncate the trajectory if the length is greater than 1100\n",
    "    if img_array.shape[0] > 1100:\n",
    "        img_array = img_array[:1100, :, :, :]\n",
    "        label_array = label_array[:1100, :]\n",
    "\n",
    "    # complement the trajectory with zeros if the length is less than 1100\n",
    "    elif img_array.shape[0] < 1100:  \n",
    "        print('sample length is {}, appending to 1100'.format(img_array.shape[0]))\n",
    "        # print('img_array.shape[0] = ', img_array.shape[0])\n",
    "        img_array = np.concatenate((img_array, np.zeros((1100 - img_array.shape[0], img_array.shape[1],img_array.shape[2],img_array.shape[3]), dtype=np.uint8)), axis=0)\n",
    "        label_array = np.concatenate((label_array, np.zeros((1100 - label_array.shape[0], label_array.shape[1]), dtype=np.float32)), axis=0)\n",
    "\n",
    "    # add the trajectory to the h5 file\n",
    "    h5_file['data'].resize((h5_file['data'].shape[0] + 1), axis=0)\n",
    "    h5_file['data'][-1, :, :, :, :] = img_array\n",
    "    h5_file['label'].resize((h5_file['label'].shape[0] + 1), axis=0)\n",
    "    h5_file['label'][-1, :, :] = label_array\n",
    "\n",
    "    \n",
    "    \n",
    "def row_count(path_csv):\n",
    "    with open(path_csv, 'r') as fileObject:\n",
    "        count = sum(1 for row in fileObject)\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3abcb-a977-4fa6-8391-f71386989b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7549c7ca-f38d-4893-9576-1e7e02fcef79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================开始处理：1678773194-747264600_labelled.csv=======================================\n",
      "preprocessing:  2023-04-01 10:24:32\n",
      "None image at: /disk3/csgo_ai_data/./data/./1678773194-747264600/1678773232-344548700.png \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_array_size = 28.97 MB\n",
      "done preprocessing:  2023-04-01 10:24:34  took time:00:00:01\n",
      "max time gap is 1s, saving as complete match\n",
      "-------------------------添加第1回合-405帧---------------------------\n",
      "sample length is 405, appending to 1100\n",
      "==========================开始处理：1678773479-138390300_labelled.csv=======================================\n",
      "preprocessing:  2023-04-01 10:24:34\n",
      "img_array_size = 1.50 MB\n",
      "done preprocessing:  2023-04-01 10:24:35  took time:00:00:00\n",
      "max time gap is 1s, saving as complete match\n",
      "-------------------------添加第2回合-21帧---------------------------\n",
      "回合行为异常，不添加\n",
      "==========================开始处理：roth-1679758279-619661300_labelled.csv=======================================\n",
      "preprocessing:  2023-04-01 10:24:35\n",
      "img_array_size = 539.23 MB\n",
      "done preprocessing:  2023-04-01 10:25:02  took time:00:00:27\n",
      "max time gap is 87s, saving as separate match\n",
      "saving separate match at 697 with interval 4 len698\n",
      "-------------------------添加第2回合-698帧---------------------------\n",
      "回合行为异常，不添加\n",
      "saving separate match at 1503 with interval 30 len1504\n",
      "-------------------------添加第2回合-1504帧---------------------------\n",
      "回合行为异常，不添加\n",
      "saving separate match at 2227 with interval 4 len2228\n",
      "-------------------------添加第2回合-2228帧---------------------------\n",
      "回合行为异常，不添加\n",
      "saving separate match at 3736 with interval 5 len3109\n",
      "-------------------------添加第2回合-3109帧---------------------------\n",
      "回合行为异常，不添加\n",
      "saving separate match at 4245 with interval 8 len0\n",
      "-------------------------添加第2回合-0帧---------------------------\n",
      "回合长度 < 20, 不添加\n",
      "saving separate match at 4845 with interval 4 len0\n",
      "-------------------------添加第2回合-0帧---------------------------\n",
      "回合长度 < 20, 不添加\n",
      "saving separate match at 5316 with interval 9 len0\n",
      "-------------------------添加第2回合-0帧---------------------------\n",
      "回合长度 < 20, 不添加\n",
      "saving separate match at 7020 with interval 87 len0\n",
      "-------------------------添加第2回合-0帧---------------------------\n",
      "回合长度 < 20, 不添加\n",
      "saving last separate match at 7537 with interval 0 len0\n",
      "-------------------------添加第2回合-0帧---------------------------\n",
      "回合长度 < 20, 不添加\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # read csv file and convert corresponding images and labels to h5 file\n",
    "    csv_head = 'mouse_x,mouse_y,click_left,click_right,scroll,w,a,s,d,r,q,e,b,1,2,3,4,5,6,7,8,9,0,shift,space,ctrl,img_path'\n",
    "    # set paths\n",
    "    base_path = '/disk3/csgo_ai_data/'\n",
    "    data_path = base_path + 'data/'\n",
    "    cleaned_path = base_path + 'cleaned_data/'\n",
    "    h5_path = base_path + 'h5_data/'\n",
    "    dataset_name = 'csgo_data_new.h5'\n",
    "    img_shape = (125, 200, 3)\n",
    "    label_len = 26\n",
    "    seg_interval = 4\n",
    "    \n",
    "    # get a list of csv files. csvs are within the cleaned_data folder and end with .csv\n",
    "    csv_list = [f for f in os.listdir(cleaned_path) if os.path.isfile(os.path.join(cleaned_path, f)) and f.endswith('.csv')]\n",
    "\n",
    "    \n",
    "    # create h5 file\n",
    "    try:\n",
    "        h5_file = h5py.File(h5_path + dataset_name, 'w')\n",
    "        # create dataset\n",
    "        h5_file.create_dataset('data', (0, 1100, img_shape[0], img_shape[1], img_shape[2]), maxshape=(None, 1100, img_shape[0], img_shape[1], img_shape[2]), dtype=np.uint8, chunks=(1,1100, img_shape[0], img_shape[1], img_shape[2]))#, compression='gzip')\n",
    "        h5_file.create_dataset('label', (0, 1100, label_len), maxshape=(None, 1100, label_len), dtype=np.float32, chunks= (1,1100,label_len))#, compression='gzip')\n",
    "        #note: the trajectory length is 1100, if scenario length is 1000, then the last 100 frames are all zeros\n",
    "\n",
    "        # read csv file and convert corresponding images and labels to h5 file\n",
    "        # multiple trajectories might be in one csv file,we segment them with the time interval in img_path\n",
    "        for csv_file in csv_list:\n",
    "            t0 = time.time()\n",
    "            print(f'==========================开始处理：{csv_file}=======================================')\n",
    "            print('preprocessing: ', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "            count = row_count(cleaned_path + csv_file)\n",
    "            with open(cleaned_path + csv_file, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                # skip the csv header\n",
    "                next(reader)\n",
    "                img_paths = [row[-1] for row in reader]\n",
    "                # fill the img_array and label_array\n",
    "                img_array, label_array = get_label_img_array(cleaned_path + csv_file,img_shape, base_path)\n",
    "                # preprocess the image\n",
    "                #img_array = img_preprocess(img_array)\n",
    "\n",
    "                # segment the trajectory based on the time interval in img_path\n",
    "                # the time interval for segmentation is 2s\n",
    "                time_list = [int(img_path.split('/')[-1].replace('.jpg','').replace('.png','').split('-')[0]) for img_path in img_paths]\n",
    "                # get the time interval\n",
    "                time_gap_list = [time_list[i] - time_list[i-1] for i in range(1, len(time_list))]\n",
    "\n",
    "                # time estimate\n",
    "                took_time = time.strftime('%H:%M:%S', time.gmtime(time.time() - t0))\n",
    "                print('done preprocessing: ', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())), ' took time:{}'.format(took_time))\n",
    "\n",
    "                # detect the time interval that is greater than 2s and segment the trajectory\n",
    "                if max(time_gap_list) < seg_interval:\n",
    "                    print(f'max time gap is {max(time_gap_list)}s, saving as complete match')           \n",
    "                    put_trajectory_to_h5(h5_file, img_array, label_array)\n",
    "                else:\n",
    "                    print(f'max time gap is {max(time_gap_list)}s, saving as separate match')           \n",
    "                    for i in range(len(time_gap_list)):\n",
    "                        if time_gap_list[i] >= seg_interval:\n",
    "                            # add the trajectory to the h5 file\n",
    "                            print(f'saving separate match at {i} with interval {time_gap_list[i]} len{img_array[:i+1].shape[0]}')\n",
    "                            put_trajectory_to_h5(h5_file, img_array[:i+1], label_array[:i+1])\n",
    "                            # remove the trajectory from the list\n",
    "                            img_array = img_array[i+1:]\n",
    "                            label_array = label_array[i+1:]\n",
    "                        if i == len(time_gap_list) - 1:\n",
    "                            # add the trajectory to the h5 file\n",
    "                            print(f'saving last separate match at {i} with interval {time_gap_list[i]} len{img_array[:i+1].shape[0]}')\n",
    "                            put_trajectory_to_h5(h5_file, img_array, label_array)\n",
    "\n",
    "    except:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        h5_file.close()\n",
    "    # close the h5 file\n",
    "    h5_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8f062-34ae-4816-aa92-f4f8ea120756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd714ea-f568-4241-8088-54bb28da3ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fca53-ea0e-443a-b353-a512eee541bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cea5f-7912-4425-b8a6-61af553a3dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79800527-833e-41c8-9df4-64e71973d952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f19b02-d2bd-4e04-add1-d63ba69d483a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
